{
  "hash": "d02496650432d6f6a3a50a02bcc0a7da",
  "result": {
    "engine": "jupyter",
    "markdown": "# Market Microstructure in Vietnam\n\n::: callout-note\nIn this chapter, we examine how the institutional design of Vietnamese equity markets, such as trading sessions, price limits, order types, and investor composition, shapes observed prices, returns, and liquidity. We quantify microstructure frictions and demonstrate why ignoring these frictions leads to biased inference in asset pricing tests.\n:::\n\nMarket microstructure is the study of how trading rules, order handling mechanisms, and market design affect price formation, transaction costs, and liquidity. The field, pioneered by @kyle1985continuous, @glosten1985bid, and @hasbrouck2007empirical, provides the analytical toolkit for understanding why observed prices may deviate from fundamental values and for how long.\n\nIn developed markets with continuous electronic trading, designated market makers, and minimal regulatory constraints on price movement, microstructure frictions are typically second-order concerns for researchers working at monthly or lower frequencies. In Vietnam's equity markets, this is emphatically not the case. Daily price limits, thin trading, a predominantly retail investor base, discrete tick sizes, and the absence of formal market-making arrangements generate frictions that propagate into monthly returns, distort factor loadings, and bias portfolio-level inference. Any serious empirical analysis of Vietnamese equities must therefore begin with a careful assessment of market microstructure.\n\nThis chapter provides that assessment. We first describe the institutional architecture of Vietnamese equity trading. We then develop diagnostics for the most consequential frictions, such as price limit hits, zero-return days, illiquidity, and non-synchronous trading, and quantify their severity in the cross-section of listed firms. Finally, we derive practical guidance for adjusting portfolio construction and asset pricing tests.\n\n## What Is Market Microstructure?\n\nThe textbook assumption of frictionless markets implies that prices continuously and costlessly incorporate information. Under this assumption, the observed return on any asset at any frequency equals the \"true\" return dictated by fundamentals. Market microstructure relaxes this assumption by recognizing that prices are generated by a specific trading process with real costs, constraints, and imperfections.\n\nThe canonical framework of @kyle1985continuous models a market with three types of participants:\n\n1.  an informed trader who knows the asset's fundamental value,\n2.  noise traders who trade for liquidity reasons, and\n3.  a market maker who sets prices to break even in expectation.\n\nThe key insight is that the market maker cannot distinguish informed from uninformed order flow, so prices adjust gradually to information, creating a wedge between the transaction price and the fundamental value. The size of this wedge (the bid-ask spread) and the speed of price adjustment (market depth) are the core objects of microstructure theory.\n\n@glosten1985bid extend this framework to a sequential trade setting and show that the bid-ask spread has two components: an adverse selection component (compensation for trading against informed traders) and an order processing component (compensation for the mechanical costs of trading). @huang1997components further decompose the spread into realized spread and price impact components. These decompositions are important because they reveal different sources of trading costs and have different implications for market quality.\n\nFor empirical asset pricing, the key question is: at what frequency and under what conditions do microstructure effects become negligible? In highly liquid markets, @bali2016empirical argue that monthly returns are largely free of microstructure contamination. In Vietnam, as we demonstrate below, this is not the case. Microstructure effects persist at monthly and even quarterly frequencies for a substantial fraction of listed firms.\n\n### The Microstructure-Asset Pricing Interface\n\nThe interface between microstructure and asset pricing operates through several channels. First, illiquidity itself may be a priced risk factor. @amihud2002illiquidity shows that expected illiquidity is positively related to expected stock returns, implying a liquidity premium. @pastor2003liquidity develop an equilibrium model in which liquidity risk (i.e., the covariance of a stock's liquidity with market liquidity) commands a risk premium. Second, microstructure noise in prices biases estimated betas, factor loadings, and test statistics. @scholes1977estimating first identified this bias in the context of non-synchronous trading, and @dimson1979risk proposed an aggregated-coefficients estimator to correct it. Third, price limits and other regulatory constraints censor the return distribution, creating truncation bias in volatility estimates, return moments, and extreme-value statistics [@kim1997price].\n\n@tbl-microstructure-interface summarizes these channels and their empirical consequences.\n\n| Channel | Mechanism | Empirical Consequence |\n|--------------------|------------------|----------------------------------|\n| Illiquidity premium | Compensation for bearing transaction costs and inventory risk | Cross-sectional return predictability by liquidity measures |\n| Non-synchronous trading | Infrequent trading creates stale prices | Downward-biased betas, attenuated correlations, and spurious lead-lag |\n| Price limits | Regulatory censoring of daily returns | Truncated return distributions, volatility spillover, and artificial autocorrelation |\n| Discrete tick sizes | Prices constrained to a grid | Bid-ask bounce, return discreteness, biased volatility |\n| Investor composition | Retail-dominated order flow | Noise trading, herding, sentiment-driven pricing |\n\n: Channels Through Which Microstructure Affects Asset Pricing {#tbl-microstructure-interface}\n\n## Trading Architecture in Vietnam\n\nVietnam operates two stock exchanges: the Ho Chi Minh Stock Exchange (HOSE), established in 2000, and the Hanoi Stock Exchange (HNX), established in 2005. HOSE lists larger firms and accounts for the majority of market capitalization and trading volume. HNX lists smaller firms and also operates the Unlisted Public Company Market (UPCoM) for firms that have not yet met full listing requirements. All three venues operate electronic limit order book systems without designated market makers.\n\n### Exchange Characteristics\n\n@tbl-exchange-comparison presents the key structural differences between HOSE, HNX, and UPCoM. These differences have direct implications for liquidity, price discovery, and the severity of microstructure frictions.\n\n| Feature               | HOSE              | HNX               | UPCoM             |\n|-------------------|------------------|------------------|------------------|\n| Established           | 2000              | 2005              | 2009              |\n| Listing tier          | Large-cap         | Mid/small-cap     | Pre-listing       |\n| Daily price limit     | $\\pm$ 7%          | $\\pm$ 10%         | $\\pm$ 15%         |\n| Tick size regime      | Tiered by price   | Tiered by price   | 100 VND           |\n| Trading lot           | 100 shares        | 100 shares        | 100 shares        |\n| Short selling         | Limited           | Not available     | Not available     |\n| Foreign ownership cap | Industry-specific | Industry-specific | Industry-specific |\n\n: Exchange Comparison: HOSE, HNX, and UPCoM {#tbl-exchange-comparison}\n\nThe heterogeneous price limit bands across exchanges create a natural experiment for studying limit effects. HOSE's tighter $\\pm$ 7% band means that large-cap stocks are more frequently constrained than mid-cap stocks on HNX, conditional on the same information shock. UPCoM's wider $\\pm$ 15% band provides the least constrained environment, though its stocks are also the least liquid.\n\n### Trading Sessions\n\nEach exchange operates a structured trading day with distinct sessions. Understanding session structure is essential because price formation mechanisms differ across sessions, and certain sessions are disproportionately important for benchmark pricing.\n\n\nThe closing auction (ATC) deserves particular attention. The ATC price is the official closing price used for index calculation, NAV computation, and margin requirements. Because it is determined by a single-bid auction, it can be manipulated by strategically timed orders, a phenomenon documented in numerous emerging markets [@comerton2009anonymity; @hillion2004manipulation]. Researchers using daily closing prices should be aware that ATC prices may not reflect the continuous-session equilibrium, particularly for less liquid stocks where a single large order can move the closing price.\n\n### Order Types and Matching Rules\n\nVietnamese exchanges support a limited set of order types compared to developed markets (@tbl-order-types).\n\n| Order Type | Description | Availability |\n|-----------------------|-------------------------|-------------------------|\n| Limit order (LO) | Specifies price and quantity | All sessions |\n| Market order (ATO/ATC) | Matches at auction price | Auction sessions only |\n| Market-to-limit (MTL) | Converts to limit at best available | HNX only |\n\n: Available Order Types {#tbl-order-types}\n\nThe absence of iceberg orders, stop orders, and hidden orders means that the full limit order book is visible to all participants. While this enhances pre-trade transparency, it also means that large institutional orders face significant information leakage risk, which may deter institutional participation and reduce market depth.\n\nOrders are matched on a strict price-time priority basis during continuous sessions. During auction sessions, a single clearing price is determined that maximizes executed volume. If multiple prices satisfy this criterion, the price closest to the previous closing price is selected.\n\n### Tick Size Structure\n\nTick sizes on HOSE are tiered by price level, which creates discontinuities in the bid-ask spread as a percentage of price.\n\n::: {#tbl-tick-sizes .cell tbl-cap='Tick Size Schedule on HOSE' execution_count=2}\n``` {.python .cell-code}\ntick_sizes = pd.DataFrame({\n    \"Price Range (VND)\": [\n        \"< 10,000\",\n        \"10,000–49,900\",\n        \"≥ 50,000\"\n    ],\n    \"Tick Size (VND)\": [10, 50, 100],\n    \"Minimum Spread as % of Midpoint\": [\n        \"0.10% at 10,000\",\n        \"0.10% at 50,000\",\n        \"0.20% at 50,000\"\n    ]\n})\n\ntick_sizes.style.hide(axis=\"index\")\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_a2204\">\n  <thead>\n    <tr>\n      <th id=\"T_a2204_level0_col0\" class=\"col_heading level0 col0\" >Price Range (VND)</th>\n      <th id=\"T_a2204_level0_col1\" class=\"col_heading level0 col1\" >Tick Size (VND)</th>\n      <th id=\"T_a2204_level0_col2\" class=\"col_heading level0 col2\" >Minimum Spread as % of Midpoint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_a2204_row0_col0\" class=\"data row0 col0\" >< 10,000</td>\n      <td id=\"T_a2204_row0_col1\" class=\"data row0 col1\" >10</td>\n      <td id=\"T_a2204_row0_col2\" class=\"data row0 col2\" >0.10% at 10,000</td>\n    </tr>\n    <tr>\n      <td id=\"T_a2204_row1_col0\" class=\"data row1 col0\" >10,000–49,900</td>\n      <td id=\"T_a2204_row1_col1\" class=\"data row1 col1\" >50</td>\n      <td id=\"T_a2204_row1_col2\" class=\"data row1 col2\" >0.10% at 50,000</td>\n    </tr>\n    <tr>\n      <td id=\"T_a2204_row2_col0\" class=\"data row2 col0\" >≥ 50,000</td>\n      <td id=\"T_a2204_row2_col1\" class=\"data row2 col1\" >100</td>\n      <td id=\"T_a2204_row2_col2\" class=\"data row2 col2\" >0.20% at 50,000</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nThe jump from a 50 VND tick to a 100 VND tick at the 50,000 VND boundary means that the minimum percentage spread doubles discontinuously. This creates a \"tick size cliff\" that can affect the cross-sectional distribution of bid-ask spreads and, consequently, the measurement of illiquidity [@vo2023minimum]. @bessembinder2003trade document similar effects in other markets with tiered tick structures.\n\n### Investor Composition\n\nThe Vietnamese equity market is predominantly driven by retail investors. While foreign institutional investors account for a meaningful share of market capitalization (particularly in blue-chip stocks subject to foreign ownership limits), daily trading volume is overwhelmingly generated by domestic retail accounts.\n\n\nThis retail dominance has several consequences for microstructure. First, retail investors tend to submit smaller orders and trade more frequently, generating high message-to-trade ratios but limited depth at each price level. Second, retail order flow is more susceptible to herding and sentiment, which can amplify momentum and generate excess volatility [@barber2009just; @kaniel2012individual]. Third, the limited institutional presence means that sophisticated liquidity provision is scarce, particularly in mid- and small-cap stocks.\n\n## Price Limits and Their Consequences\n\nVietnam enforces daily price limits on all listed equities. A stock's price cannot move beyond a fixed percentage of the previous day's closing price within a single trading day. The limit bands are $\\pm$ 7% on HOSE, $\\pm$ 10% on HNX, and $\\pm$ 15% on UPCoM.\n\n### Theoretical Framework\n\nPrice limits were introduced with the stated goal of reducing volatility and preventing panic-driven price dislocations. However, the academic literature presents a more nuanced picture. The \"magnet effect\" hypothesis [@subrahmanyam1994circuit] predicts that price limits actually accelerate price movement toward the limit as traders rush to execute before the limit is hit. The \"delayed price discovery\" hypothesis [@Fama1989] argues that limits merely postpone inevitable price adjustments, creating volatility spillover into subsequent days.\n\nFormally, let $P_t^*$ denote the equilibrium price on day $t$ and $P_{t-1}^c$ the previous closing price. The observed return is:\n\n$$\nr_t^{obs} = \\begin{cases}\n\\bar{L} & \\text{if } r_t^* \\geq \\bar{L} \\\\\nr_t^* & \\text{if } \\underline{L} < r_t^* < \\bar{L} \\\\\n\\underline{L} & \\text{if } r_t^* \\leq \\underline{L}\n\\end{cases}\n$$ {#eq-price-limit}\n\nwhere $r_t^* = \\ln(P_t^* / P_{t-1}^c)$ is the latent (unconstrained) return, $\\bar{L}$ is the upper limit, and $\\underline{L}$ is the lower limit. The observed return $r_t^{obs}$ is a censored version of the true return. This censoring has several consequences:\n\n1.  **Truncated moments**: The observed variance $\\text{Var}(r_t^{obs}) < \\text{Var}(r_t^*)$ because extreme returns are clipped. This biases downward any volatility-based risk measure.\n\n2.  **Artificial autocorrelation**: When $r_t^{obs} = \\bar{L}$ and $r_{t+1}^{obs} > 0$ (continued adjustment the next day), the return series exhibits positive autocorrelation that is purely mechanical, not informational.\n\n3.  **Volatility spillover**: Define excess volatility on day $t+1$ as $\\sigma_{t+1}^2 - E[\\sigma_{t+1}^2 | \\text{no limit hit on day } t]$. @kim1997price and @chu2019forecasting document significant positive spillover, where days following limit hits exhibit abnormally high volatility.\n\n4.  **Biased extreme value statistics**: Measures such as Value-at-Risk, Expected Shortfall, and maximum drawdown are mechanically bounded by the limit, understating true tail risk.\n\n### Detecting Price Limit Hits\n\nWe now implement a diagnostic to detect price limit hits in the daily data.\n\n::: {#detect-limit-hits .cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport sqlite3\n\n# Load daily price data\ntidy_finance = sqlite3.connect(database=\"data/tidy_finance_python.sqlite\")\n\n# Assume prices_daily contains: symbol, date, close, exchange\nprices_daily = pd.read_sql_query(\n    # , exchange\n    sql=\"\"\"\n        SELECT symbol, date, close\n        FROM prices_daily\n    \"\"\",\n    con=tidy_finance,\n    parse_dates=[\"date\"]\n).dropna()\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Define limit bands by exchange\nlimit_bands = {\"HOSE\": 0.07, \"HNX\": 0.10, \"UPCoM\": 0.15}\n\nprices_daily = prices_daily.sort_values([\"symbol\", \"date\"])\nprices_daily[\"prev_close\"] = prices_daily.groupby(\"symbol\")[\"close\"].shift(1)\nprices_daily[\"ret\"] = prices_daily[\"close\"] / prices_daily[\"prev_close\"] - 1\nprices_daily[\"limit_band\"] = prices_daily[\"exchange\"].map(limit_bands)\n\n# A limit hit occurs when the return is within 0.1% of the theoretical limit\ntolerance = 0.001\nprices_daily[\"upper_hit\"] = (\n    prices_daily[\"ret\"] >= prices_daily[\"limit_band\"] - tolerance\n)\nprices_daily[\"lower_hit\"] = (\n    prices_daily[\"ret\"] <= -prices_daily[\"limit_band\"] + tolerance\n)\nprices_daily[\"limit_hit\"] = (\n    prices_daily[\"upper_hit\"] | prices_daily[\"lower_hit\"]\n)\n```\n:::\n\n\n### Frequency of Limit Hits\n\n::: {#fig-limit-hit-frequency .cell execution_count=6}\n``` {.python .cell-code}\nprices_daily[\"year_month\"] = prices_daily[\"date\"].dt.to_period(\"M\")\n\nlimit_hit_monthly = (\n    prices_daily\n    .groupby([\"year_month\", \"exchange\"])\n    .agg(\n        total_obs=(\"limit_hit\", \"count\"),\n        limit_hits=(\"limit_hit\", \"sum\")\n    )\n    .reset_index()\n)\nlimit_hit_monthly[\"hit_rate\"] = (\n    limit_hit_monthly[\"limit_hits\"] / limit_hit_monthly[\"total_obs\"]\n)\nlimit_hit_monthly[\"date\"] = limit_hit_monthly[\"year_month\"].dt.to_timestamp()\n\nfig, ax = plt.subplots(figsize=(8, 4))\n\nfor exchange, color in zip(\n    [\"HOSE\", \"HNX\", \"UPCoM\"], [\"#2C73D2\", \"#FF6B6B\", \"#5DCEAF\"]\n):\n    subset = limit_hit_monthly[limit_hit_monthly[\"exchange\"] == exchange]\n    ax.plot(\n        subset[\"date\"], subset[\"hit_rate\"] * 100,\n        label=exchange, color=color, linewidth=1.2\n    )\n\nax.set_ylabel(\"Limit Hit Rate (%)\")\nax.set_xlabel(\"\")\nax.legend(frameon=False)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n### Volatility Spillover Test\n\nFollowing @kim1997price, we test whether days following a limit hit exhibit abnormally high volatility. Define the dummy variable $D_t = 1$ if a limit hit occurred on day $t$, and estimate:\n\n$$\n\\sigma_{t+1}^2 = \\alpha + \\beta D_t + \\gamma \\sigma_t^2 + \\varepsilon_{t+1}\n$$ {#eq-vol-spillover}\n\nwhere $\\sigma_t^2$ is the squared return. A positive and significant $\\beta$ indicates volatility spillover attributable to the price limit.\n\n::: {#volatility-spillover-test .cell execution_count=7}\n``` {.python .cell-code}\nimport statsmodels.api as sm\n\n# Panel-level volatility spillover test\nprices_daily[\"sq_ret\"] = prices_daily[\"ret\"] ** 2\nprices_daily[\"sq_ret_lead\"] = prices_daily.groupby(\"symbol\")[\"sq_ret\"].shift(-1)\nprices_daily[\"limit_hit_int\"] = prices_daily[\"limit_hit\"].astype(int)\n\nspillover_data = prices_daily.dropna(subset=[\"sq_ret_lead\", \"sq_ret\"])\n\nX = sm.add_constant(spillover_data[[\"limit_hit_int\", \"sq_ret\"]])\ny = spillover_data[\"sq_ret_lead\"]\n\nmodel = sm.OLS(y, X).fit(cov_type=\"cluster\", cov_kwds={\"groups\": spillover_data[\"symbol\"]})\n\nspillover_results = pd.DataFrame({\n    \"Coefficient\": model.params,\n    \"Std. Error\": model.bse,\n    \"t-stat\": model.tvalues,\n    \"p-value\": model.pvalues\n}).round(6)\n\nprint(spillover_results)\n```\n:::\n\n\n::: callout-tip\nA significant positive coefficient on the limit hit dummy confirms that Vietnamese price limits do not eliminate volatility, they merely redistribute it across days. This has direct implications for risk management: daily VaR measures computed from censored returns understate true risk exposure.\n:::\n\n### Return Autocorrelation Induced by Price Limits\n\nPrice limits mechanically induce positive autocorrelation in returns. To quantify this, we compute the first-order autocorrelation coefficient separately for stocks that hit limits frequently versus those that do not.\n\n::: {#tbl-autocorrelation-by-limit .cell tbl-cap='Return Autocorrelation by Price Limit Hit Frequency' execution_count=8}\n``` {.python .cell-code}\n# Classify stocks by limit hit frequency\nstock_limit_freq = (\n    prices_daily\n    .groupby(\"symbol\")\n    .agg(\n        hit_rate=(\"limit_hit\", \"mean\"),\n        n_obs=(\"ret\", \"count\")\n    )\n    .query(\"n_obs >= 250\")  # At least 1 year of data\n)\n\nstock_limit_freq[\"limit_group\"] = pd.qcut(\n    stock_limit_freq[\"hit_rate\"], q=3,\n    labels=[\"Low\", \"Medium\", \"High\"]\n)\n\n# Compute autocorrelation by group\ndef compute_autocorr(group_symbols):\n    subset = prices_daily[prices_daily[\"symbol\"].isin(group_symbols)].copy()\n    subset[\"ret_lag\"] = subset.groupby(\"symbol\")[\"ret\"].shift(1)\n    return subset[[\"ret\", \"ret_lag\"]].dropna().corr().iloc[0, 1]\n\nautocorr_results = []\nfor group in [\"Low\", \"Medium\", \"High\"]:\n    symbols = stock_limit_freq[stock_limit_freq[\"limit_group\"] == group].index\n    ac = compute_autocorr(symbols)\n    n_stocks = len(symbols)\n    avg_hit_rate = stock_limit_freq.loc[symbols, \"hit_rate\"].mean()\n    autocorr_results.append({\n        \"Group\": group,\n        \"N Stocks\": n_stocks,\n        \"Avg Limit Hit Rate (%)\": round(avg_hit_rate * 100, 2),\n        \"AR(1)\": round(ac, 4)\n    })\n\npd.DataFrame(autocorr_results).style.hide(axis=\"index\")\n```\n:::\n\n\nThe expected pattern is a monotonically increasing autocorrelation from the Low to High limit-hit group, confirming that the observed serial dependence in returns is at least partly an artifact of price censoring rather than genuine return predictability.\n\n## Liquidity, Thin Trading, and Zero Returns\n\nLiquidity (i.e., the ability to trade quickly at low cost without moving the price) is a first-order concern in Vietnamese equities. A substantial fraction of listed firms, particularly on HNX and UPCoM, experience chronic illiquidity characterized by infrequent trading, wide bid-ask spreads, and frequent zero-return days.\n\n### Measuring Liquidity\n\nThe academic literature has developed numerous liquidity measures, each capturing a different dimension of market quality. @#tbl-liquidity-measures summarizes the measures most applicable to Vietnamese data, given typical data availability.\n\n| Measure | Formula | Interpretation | Data Required |\n|------------------|------------------|------------------|------------------|\n| Turnover ratio | $\\text{TO}_{i,t} = \\frac{\\text{Volume}_{i,t}}{\\text{Shares Outstanding}_{i}}$ | Trading intensity relative to float | Volume, shares outstanding |\n| Amihud illiquidity | $\\text{ILLIQ}_{i,t} = \\frac{1}{D} \\sum_{d=1}^{D} \\frac{|r_{i,d}|}{V_{i,d}}$ | Price impact per unit of volume | Daily returns, daily volume |\n| Zero-return proportion | $\\text{ZR}_{i,t} = \\frac{\\#\\{d : r_{i,d} = 0\\}}{D}$ | Frequency of non-trading or stale pricing | Daily returns |\n| Roll spread | $\\hat{S}_i = 2\\sqrt{-\\text{Cov}(r_{i,d}, r_{i,d-1})}$ | Effective bid-ask spread estimate | Daily returns |\n| Bid-ask spread | $\\text{BA}_{i,d} = \\frac{\\text{Ask}_{i,d} - \\text{Bid}_{i,d}}{(\\text{Ask}_{i,d} + \\text{Bid}_{i,d})/2}$ | Direct transaction cost | Quote data |\n\n: Liquidity Measures for Vietnamese Equities {#tbl-liquidity-measures}\n\nThe Amihud illiquidity ratio [@amihud2002illiquidity] is particularly useful because it requires only daily return and volume data. It captures the price impact of trading (i.e., the return per unit of currency volume) and has been shown to correlate well with more sophisticated microstructure-based measures such as the effective spread [see @goyenko2009liquidity and @goyenko2009stock for a comprehensive comparison].\n\n### Computing Liquidity Diagnostics\n\n::: {#compute-liquidity .cell execution_count=9}\n``` {.python .cell-code}\n# Compute standard liquidity measures at the stock-month level\nprices_daily[\"abs_ret\"] = prices_daily[\"ret\"].abs()\nprices_daily[\"zero_return\"] = (prices_daily[\"ret\"] == 0).astype(int)\nprices_daily[\"year_month\"] = prices_daily[\"date\"].dt.to_period(\"M\")\n\n# Assume volume is in shares and value is in VND\n# Amihud: average |ret| / value (in billions VND)\nprices_daily[\"amihud_daily\"] = np.where(\n    prices_daily[\"value\"] > 0,\n    prices_daily[\"abs_ret\"] / (prices_daily[\"value\"] / 1e9),\n    np.nan\n)\n\nliquidity_monthly = (\n    prices_daily\n    .groupby([\"symbol\", \"year_month\"])\n    .agg(\n        zero_return_share=(\"zero_return\", \"mean\"),\n        avg_turnover=(\"turnover\", \"mean\"),\n        amihud=(\"amihud_daily\", \"mean\"),\n        trading_days=(\"ret\", \"count\"),\n        avg_daily_value=(\"value\", \"mean\")\n    )\n    .reset_index()\n)\n\n# Flag severely illiquid stock-months\nliquidity_monthly[\"illiquid_flag\"] = (\n    (liquidity_monthly[\"zero_return_share\"] > 0.5) |\n    (liquidity_monthly[\"trading_days\"] < 10) |\n    (liquidity_monthly[\"avg_daily_value\"] < 1e8)  # < 100M VND/day\n)\n```\n:::\n\n\n### Cross-Sectional Distribution of Liquidity\n\n::: {#tbl-liquidity-distribution .cell tbl-cap='Cross-Sectional Distribution of Liquidity Measures (Latest Full Year)' execution_count=10}\n``` {.python .cell-code}\nlatest_year = liquidity_monthly[\"year_month\"].dt.year.max()\nannual_liq = (\n    liquidity_monthly[liquidity_monthly[\"year_month\"].dt.year == latest_year]\n    .groupby(\"symbol\")\n    .agg(\n        zero_return_share=(\"zero_return_share\", \"mean\"),\n        avg_turnover=(\"avg_turnover\", \"mean\"),\n        amihud=(\"amihud\", \"mean\"),\n        avg_daily_value_m=(\"avg_daily_value\", lambda x: x.mean() / 1e6)\n    )\n)\n\nsummary_stats = annual_liq.describe(percentiles=[0.10, 0.25, 0.50, 0.75, 0.90]).T\nsummary_stats = summary_stats[\n    [\"mean\", \"std\", \"10%\", \"25%\", \"50%\", \"75%\", \"90%\"]\n].round(4)\nsummary_stats.columns = [\"Mean\", \"Std\", \"P10\", \"P25\", \"Median\", \"P75\", \"P90\"]\nsummary_stats.index = [\n    \"Zero-Return Share\",\n    \"Avg Daily Turnover\",\n    \"Amihud Illiquidity\",\n    \"Avg Daily Value (M VND)\"\n]\nsummary_stats\n```\n:::\n\n\n### Liquidity Distribution Across Exchanges\n\n::: {#fig-liquidity-by-exchange .cell execution_count=11}\n``` {.python .cell-code}\n# Merge exchange info\nstock_exchange = (\n    prices_daily[[\"symbol\", \"exchange\"]]\n    .drop_duplicates(\"symbol\")\n)\nannual_liq_exch = annual_liq.merge(\n    stock_exchange, left_index=True, right_on=\"symbol\"\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# Zero-return share\nfor exchange, color in zip(\n    [\"HOSE\", \"HNX\", \"UPCoM\"], [\"#2C73D2\", \"#FF6B6B\", \"#5DCEAF\"]\n):\n    subset = annual_liq_exch[annual_liq_exch[\"exchange\"] == exchange]\n    axes[0].hist(\n        subset[\"zero_return_share\"], bins=30, alpha=0.6,\n        color=color, label=exchange, density=True\n    )\naxes[0].set_xlabel(\"Zero-Return Share\")\naxes[0].set_ylabel(\"Density\")\naxes[0].legend(frameon=False)\naxes[0].spines[\"top\"].set_visible(False)\naxes[0].spines[\"right\"].set_visible(False)\n\n# Amihud (log scale)\nfor exchange, color in zip(\n    [\"HOSE\", \"HNX\", \"UPCoM\"], [\"#2C73D2\", \"#FF6B6B\", \"#5DCEAF\"]\n):\n    subset = annual_liq_exch[annual_liq_exch[\"exchange\"] == exchange]\n    amihud_log = np.log(subset[\"amihud\"].clip(lower=1e-10))\n    axes[1].hist(\n        amihud_log, bins=30, alpha=0.6,\n        color=color, label=exchange, density=True\n    )\naxes[1].set_xlabel(\"Log Amihud Illiquidity\")\naxes[1].set_ylabel(\"Density\")\naxes[1].legend(frameon=False)\naxes[1].spines[\"top\"].set_visible(False)\naxes[1].spines[\"right\"].set_visible(False)\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nThe distributions typically reveal a bimodal pattern: HOSE stocks cluster at low illiquidity values, while HNX and especially UPCoM stocks exhibit a long right tail of extreme illiquidity. This heterogeneity implies that a single liquidity filter or treatment is insufficient for the entire cross-section.\n\n### Time Variation in Aggregate Liquidity\n\nMarket-wide liquidity is not constant. It deteriorates during crises, policy uncertainty, and periods of capital outflow, and improves during bull markets and periods of foreign inflow. The time variation in aggregate liquidity is itself a risk factor [@pastor2003liquidity].\n\n::: {#fig-aggregate-liquidity .cell execution_count=12}\n``` {.python .cell-code}\nagg_liquidity = (\n    liquidity_monthly\n    .groupby(\"year_month\")\n    .agg(\n        median_amihud=(\"amihud\", \"median\"),\n        median_zero_ret=(\"zero_return_share\", \"median\"),\n        total_value=(\"avg_daily_value\", \"sum\")\n    )\n    .reset_index()\n)\nagg_liquidity[\"date\"] = agg_liquidity[\"year_month\"].dt.to_timestamp()\n\nfig, ax1 = plt.subplots(figsize=(8, 4))\n\nax1.plot(\n    agg_liquidity[\"date\"],\n    np.log(agg_liquidity[\"median_amihud\"].clip(lower=1e-10)),\n    color=\"#2C73D2\", linewidth=1.2\n)\nax1.set_ylabel(\"Log Median Amihud\", color=\"#2C73D2\")\nax1.tick_params(axis=\"y\", labelcolor=\"#2C73D2\")\n\nax2 = ax1.twinx()\nax2.fill_between(\n    agg_liquidity[\"date\"],\n    agg_liquidity[\"median_zero_ret\"] * 100,\n    alpha=0.3, color=\"#FF6B6B\"\n)\nax2.set_ylabel(\"Median Zero-Return Share (%)\", color=\"#FF6B6B\")\nax2.tick_params(axis=\"y\", labelcolor=\"#FF6B6B\")\n\nax1.spines[\"top\"].set_visible(False)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n::: callout-important\n## Practical Recommendation\n\nBefore any asset pricing analysis, apply the following liquidity filter: exclude stock-months where the zero-return share exceeds 50%, where fewer than 15 trading days are observed, or where average daily trading value falls below a threshold (e.g., 100 million VND). Document the filter explicitly, and report sensitivity of results to alternative thresholds.\n:::\n\n## Bid-Ask Spread Estimation\n\nIn the absence of comprehensive quote data, the effective bid-ask spread can be estimated from transaction data using the method of @roll1984simple. The Roll estimator exploits the fact that if the bid-ask bounce is the sole source of negative serial covariance in returns, then:\n\n$$\n\\hat{S}_{\\text{Roll}} = 2\\sqrt{-\\text{Cov}(\\Delta p_t, \\Delta p_{t-1})}\n$$ {#eq-roll}\n\nwhere $\\Delta p_t = p_t - p_{t-1}$ is the price change. When the autocovariance is positive (which occurs when information-driven serial correlation dominates the bid-ask bounce), the Roll estimator is undefined. @hasbrouck2009trading proposes a Bayesian variant that handles this case by imposing a prior on the spread.\n\n::: {#compute-roll-spread .cell execution_count=13}\n``` {.python .cell-code}\n# Compute Roll spread estimate at the stock-month level\nprices_daily[\"dprice\"] = prices_daily.groupby(\"symbol\")[\"close\"].diff()\nprices_daily[\"dprice_lag\"] = prices_daily.groupby(\"symbol\")[\"dprice\"].shift(1)\n\nroll_cov = (\n    prices_daily\n    .groupby([\"symbol\", \"year_month\"])\n    .apply(\n        lambda g: g[[\"dprice\", \"dprice_lag\"]].dropna().cov().iloc[0, 1],\n        include_groups=False\n    )\n    .reset_index(name=\"autocovariance\")\n)\n\n# Roll spread is defined only when autocovariance is negative\nroll_cov[\"roll_spread\"] = np.where(\n    roll_cov[\"autocovariance\"] < 0,\n    2 * np.sqrt(-roll_cov[\"autocovariance\"]),\n    np.nan\n)\n\n# As a percentage of price\nroll_cov = roll_cov.merge(\n    prices_daily.groupby([\"symbol\", \"year_month\"])[\"close\"].mean()\n    .reset_index(name=\"avg_price\"),\n    on=[\"symbol\", \"year_month\"]\n)\nroll_cov[\"roll_spread_pct\"] = roll_cov[\"roll_spread\"] / roll_cov[\"avg_price\"] * 100\n```\n:::\n\n\n::: {#tbl-roll-spread-summary .cell tbl-cap='Distribution of Roll Spread Estimates (% of Price)' execution_count=14}\n``` {.python .cell-code}\nroll_summary = (\n    roll_cov\n    .dropna(subset=[\"roll_spread_pct\"])\n    .groupby(\"year_month\")[\"roll_spread_pct\"]\n    .describe(percentiles=[0.25, 0.50, 0.75])\n    .reset_index()\n)\n\n# Show latest year summary\nlatest_year_roll = roll_cov[\n    roll_cov[\"year_month\"].dt.year == roll_cov[\"year_month\"].dt.year.max()\n]\nprint(\n    latest_year_roll[\"roll_spread_pct\"]\n    .dropna()\n    .describe(percentiles=[0.10, 0.25, 0.50, 0.75, 0.90])\n    .round(3)\n)\n```\n:::\n\n\n## Non-Synchronous Trading Bias\n\nWhen stocks do not trade at the same frequency or at the same times, observed returns are misaligned. This non-synchronous trading bias, first formalized by @scholes1977estimating and @lo1990econometric, is one of the most consequential microstructure effects for asset pricing in thin markets.\n\n### The Problem\n\nSuppose the true (unobserved) return process for stock $i$ follows a single-factor model:\n\n$$\nr_{i,t}^* = \\alpha_i + \\beta_i r_{m,t}^* + \\varepsilon_{i,t}\n$$ {#eq-true-factor}\n\nwhere $r_{m,t}^*$ is the true market return and $\\beta_i$ is the true beta. If stock $i$ last traded $k$ days before the end of day $t$, the observed return incorporates information only up to day $t - k$. @scholes1977estimating show that the OLS estimate of beta from regressing observed returns on observed market returns is:\n\n$$\n\\hat{\\beta}_i^{OLS} = \\beta_i \\cdot \\pi_i\n$$ {#eq-beta-bias}\n\nwhere $\\pi_i$ is the probability that stock $i$ trades on any given day. For a stock that trades on only 50% of days, the OLS beta is biased downward by 50%. This bias is severe in Vietnam, where many small-cap stocks trade on fewer than half of all trading days.\n\n### Quantifying the Bias\n\n::: {#fig-trading-frequency .cell execution_count=15}\n``` {.python .cell-code}\n# Compute trading frequency: proportion of market days with nonzero volume\nmarket_days = prices_daily.groupby(\"year_month\")[\"date\"].nunique()\ntrading_freq = (\n    prices_daily[prices_daily[\"value\"] > 0]\n    .groupby([\"symbol\", \"year_month\"])[\"date\"]\n    .nunique()\n    .reset_index(name=\"days_traded\")\n)\ntrading_freq = trading_freq.merge(\n    market_days.reset_index().rename(columns={\"date\": \"market_days\"}),\n    on=\"year_month\"\n)\ntrading_freq[\"trade_prob\"] = trading_freq[\"days_traded\"] / trading_freq[\"market_days\"]\n\n# Annual average\nannual_trade_freq = (\n    trading_freq\n    .groupby(\"symbol\")[\"trade_prob\"]\n    .mean()\n    .reset_index(name=\"avg_trade_prob\")\n)\n\nfig, ax = plt.subplots(figsize=(7, 4))\nax.hist(\n    annual_trade_freq[\"avg_trade_prob\"], bins=50,\n    color=\"#2C73D2\", edgecolor=\"white\", alpha=0.8\n)\nax.axvline(\n    annual_trade_freq[\"avg_trade_prob\"].median(),\n    color=\"#FF6B6B\", linestyle=\"--\", linewidth=1.5,\n    label=f\"Median = {annual_trade_freq['avg_trade_prob'].median():.2f}\"\n)\nax.set_xlabel(\"Average Trading Probability (Fraction of Market Days)\")\nax.set_ylabel(\"Number of Stocks\")\nax.legend(frameon=False)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n### The Dimson Beta Correction\n\n@dimson1979risk proposes a simple correction: include lagged and leading market returns in the beta regression:\n\n$$\nr_{i,t} = \\alpha_i + \\sum_{k=-K}^{K} \\beta_{i,k} \\, r_{m,t-k} + \\varepsilon_{i,t}\n$$ {#eq-dimson}\n\nThe Dimson-corrected beta is $\\hat{\\beta}_i^{Dimson} = \\sum_{k=-K}^{K} \\hat{\\beta}_{i,k}$. Typically $K = 1$ or $K = 2$ is sufficient. The summed coefficients capture the full response of the stock's observed return to market information, regardless of when the stock actually trades.\n\n::: {#dimson-beta-estimation .cell execution_count=16}\n``` {.python .cell-code}\n# Estimate Dimson betas with K=1 lag and lead\n# Merge market return\nmarket_ret = (\n    prices_daily\n    .groupby(\"date\")\n    .apply(\n        lambda g: np.average(g[\"ret\"].dropna(), weights=g[\"mktcap\"].loc[g[\"ret\"].dropna().index])\n        if g[\"ret\"].dropna().shape[0] > 0 else np.nan,\n        include_groups=False\n    )\n    .reset_index(name=\"rm\")\n)\n\nprices_daily = prices_daily.merge(market_ret, on=\"date\", how=\"left\")\nprices_daily[\"rm_lag1\"] = prices_daily.groupby(\"symbol\")[\"rm\"].shift(1)\nprices_daily[\"rm_lead1\"] = prices_daily.groupby(\"symbol\")[\"rm\"].shift(-1)\n\ndef estimate_dimson_beta(group):\n    \"\"\"Estimate OLS and Dimson(K=1) betas for a single stock.\"\"\"\n    g = group.dropna(subset=[\"ret\", \"rm\", \"rm_lag1\", \"rm_lead1\"])\n    if len(g) < 60:\n        return pd.Series({\"beta_ols\": np.nan, \"beta_dimson\": np.nan, \"n_obs\": len(g)})\n\n    # OLS beta\n    X_ols = sm.add_constant(g[\"rm\"])\n    ols_model = sm.OLS(g[\"ret\"], X_ols).fit()\n    beta_ols = ols_model.params[\"rm\"]\n\n    # Dimson beta\n    X_dim = sm.add_constant(g[[\"rm_lag1\", \"rm\", \"rm_lead1\"]])\n    dim_model = sm.OLS(g[\"ret\"], X_dim).fit()\n    beta_dimson = dim_model.params[[\"rm_lag1\", \"rm\", \"rm_lead1\"]].sum()\n\n    return pd.Series({\n        \"beta_ols\": beta_ols,\n        \"beta_dimson\": beta_dimson,\n        \"n_obs\": len(g)\n    })\n\nbeta_comparison = (\n    prices_daily\n    .groupby(\"symbol\")\n    .apply(estimate_dimson_beta, include_groups=False)\n    .reset_index()\n)\n```\n:::\n\n\n::: {#fig-beta-comparison .cell execution_count=17}\n``` {.python .cell-code}\nbeta_valid = beta_comparison.dropna()\n\nfig, ax = plt.subplots(figsize=(6, 6))\nax.scatter(\n    beta_valid[\"beta_ols\"], beta_valid[\"beta_dimson\"],\n    alpha=0.3, s=10, color=\"#2C73D2\"\n)\nlims = [\n    min(ax.get_xlim()[0], ax.get_ylim()[0]),\n    max(ax.get_xlim()[1], ax.get_ylim()[1])\n]\nax.plot(lims, lims, \"--\", color=\"gray\", linewidth=1)\nax.set_xlabel(\"OLS Beta\")\nax.set_ylabel(\"Dimson Beta (K=1)\")\nax.set_aspect(\"equal\")\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nThe scatter plot should reveal a systematic pattern: Dimson betas exceed OLS betas for most stocks, with the discrepancy largest for thinly traded stocks. Points above the 45-degree line indicate stocks whose OLS betas are biased downward by non-synchronous trading.\n\n::: {#tbl-beta-bias-by-liquidity .cell tbl-cap='Beta Bias by Trading Frequency Tercile' execution_count=18}\n``` {.python .cell-code}\nbeta_with_freq = beta_valid.merge(annual_trade_freq, on=\"symbol\")\nbeta_with_freq[\"freq_tercile\"] = pd.qcut(\n    beta_with_freq[\"avg_trade_prob\"], q=3,\n    labels=[\"Low (Thin)\", \"Medium\", \"High (Liquid)\"]\n)\n\nbeta_bias_summary = (\n    beta_with_freq\n    .groupby(\"freq_tercile\")\n    .agg(\n        n_stocks=(\"symbol\", \"count\"),\n        avg_trade_prob=(\"avg_trade_prob\", \"mean\"),\n        mean_beta_ols=(\"beta_ols\", \"mean\"),\n        mean_beta_dimson=(\"beta_dimson\", \"mean\"),\n        median_beta_ols=(\"beta_ols\", \"median\"),\n        median_beta_dimson=(\"beta_dimson\", \"median\")\n    )\n    .round(3)\n)\n\nbeta_bias_summary[\"bias_pct\"] = (\n    (beta_bias_summary[\"mean_beta_dimson\"] - beta_bias_summary[\"mean_beta_ols\"])\n    / beta_bias_summary[\"mean_beta_dimson\"] * 100\n).round(1)\n\nbeta_bias_summary\n```\n:::\n\n\n::: callout-warning\nFor the thinnest-traded tercile, OLS beta underestimates true systematic risk by 20-40% on average. Using uncorrected betas for cost of equity estimation or factor model tests will produce systematically incorrect results for these stocks.\n:::\n\n### The Scholes-Williams Estimator\n\nAn alternative correction, proposed by @scholes1977estimating, estimates beta as:\n\n$$\n\\hat{\\beta}_i^{SW} = \\frac{\\hat{\\beta}_{i,-1} + \\hat{\\beta}_{i,0} + \\hat{\\beta}_{i,+1}}{1 + 2\\hat{\\rho}_m}\n$$ {#eq-sw}\n\nwhere $\\hat{\\beta}_{i,k}$ is the slope from regressing $r_{i,t}$ on $r_{m,t-k}$ alone, and $\\hat{\\rho}_m$ is the first-order autocorrelation of the market return. The Scholes-Williams estimator is consistent under the assumption that non-trading is the sole source of serial cross-correlation, while the Dimson estimator is more robust to additional sources of lead-lag structure.\n\n::: {#scholes-williams-beta .cell execution_count=19}\n``` {.python .cell-code}\ndef estimate_sw_beta(group):\n    \"\"\"Estimate Scholes-Williams beta.\"\"\"\n    g = group.dropna(subset=[\"ret\", \"rm\", \"rm_lag1\", \"rm_lead1\"])\n    if len(g) < 60:\n        return np.nan\n\n    # Separate regressions\n    beta_lag = sm.OLS(g[\"ret\"], sm.add_constant(g[\"rm_lag1\"])).fit().params.iloc[1]\n    beta_0 = sm.OLS(g[\"ret\"], sm.add_constant(g[\"rm\"])).fit().params.iloc[1]\n    beta_lead = sm.OLS(g[\"ret\"], sm.add_constant(g[\"rm_lead1\"])).fit().params.iloc[1]\n\n    # Market autocorrelation\n    rho_m = g[\"rm\"].autocorr(lag=1)\n\n    beta_sw = (beta_lag + beta_0 + beta_lead) / (1 + 2 * rho_m)\n    return beta_sw\n\nbeta_comparison[\"beta_sw\"] = (\n    prices_daily\n    .groupby(\"symbol\")\n    .apply(estimate_sw_beta, include_groups=False)\n    .values\n)\n```\n:::\n\n\n## Implications for Portfolio Construction\n\nThe microstructure frictions documented above have direct consequences for portfolio construction, particularly for strategies that involve rebalancing across the full cross-section of listed firms.\n\n### Equal-Weighted vs. Value-Weighted Returns\n\nEqual-weighted portfolio returns give the same weight to each stock, including illiquid small-cap stocks that may contribute stale or noisy prices. Value-weighted returns tilt toward large, liquid stocks and are less susceptible to microstructure contamination.\n\n::: {#fig-ew-vs-vw .cell execution_count=20}\n``` {.python .cell-code}\nmonthly_returns = (\n    prices_daily\n    .groupby([\"symbol\", \"year_month\"])\n    .agg(\n        monthly_ret=(\"ret\", lambda x: (1 + x).prod() - 1),\n        last_mktcap=(\"mktcap\", \"last\")\n    )\n    .reset_index()\n)\nmonthly_returns[\"date\"] = monthly_returns[\"year_month\"].dt.to_timestamp()\n\n# Equal-weighted\new_ret = monthly_returns.groupby(\"date\")[\"monthly_ret\"].mean().reset_index(name=\"ew\")\n\n# Value-weighted\ndef vw_return(group):\n    w = group[\"last_mktcap\"] / group[\"last_mktcap\"].sum()\n    return (w * group[\"monthly_ret\"]).sum()\n\nvw_ret = (\n    monthly_returns.groupby(\"date\")\n    .apply(vw_return, include_groups=False)\n    .reset_index(name=\"vw\")\n)\n\nport_comp = ew_ret.merge(vw_ret, on=\"date\")\n\nfig, ax = plt.subplots(figsize=(8, 4))\nfor col, label, color in [\n    (\"ew\", \"Equal-Weighted\", \"#FF6B6B\"),\n    (\"vw\", \"Value-Weighted\", \"#2C73D2\")\n]:\n    cum_ret = (1 + port_comp[col]).cumprod()\n    ax.plot(port_comp[\"date\"], cum_ret, label=label, color=color, linewidth=1.2)\n\nax.set_ylabel(\"Cumulative Return (Growth of 1 VND)\")\nax.set_xlabel(\"\")\nax.legend(frameon=False)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nA persistent divergence between equal-weighted and value-weighted cumulative returns is a hallmark of microstructure effects: the equal-weighted portfolio overstates attainable returns because it implicitly assumes costless trading in illiquid stocks.\n\n### Recommended Liquidity Filters\n\nBased on the diagnostics developed in this chapter, we recommend the following pre-analysis filters:\n\n\n::: callout-tip\nAlways report results with and without liquidity filters. If results are qualitatively different, the baseline findings may be driven by microstructure artifacts rather than genuine economic effects.\n:::\n\n### Monthly vs. Daily Frequency\n\nFor most asset pricing applications, monthly return aggregation is preferable to daily analysis in Vietnam because:\n\n1.  Monthly returns smooth out intraday noise, bid-ask bounce, and price limit effects.\n2.  Stocks that trade infrequently within a month still produce a meaningful monthly return.\n3.  Factor portfolio sorts are conventionally conducted at monthly frequency.\n4.  Statistical tests have better size properties when microstructure noise is reduced.\n\nHowever, monthly aggregation does not eliminate all biases. Stocks with zero returns for an entire month still contribute stale observations. The Dimson and Scholes-Williams corrections should still be applied at monthly frequency for beta estimation.\n\n## Implications for Asset Pricing Tests\n\n### Factor Model Estimation\n\nStandard factor model estimation assumes that returns are observed synchronously and without censoring. In Vietnam, both assumptions are violated. The practical consequences are in @tbl-assumption-violations\n\n| Assumption | Violation in Vietnam | Consequence |\n|-------------------|--------------------------------|---------------------|\n| Synchronous observation | Thin trading | Biased betas, attenuated R² |\n| Uncensored returns | Price limits | Truncated distributions, biased moments |\n| Continuous trading | Discrete ticks | Return discreteness, bid-ask bounce |\n| No transaction costs | Wide spreads | Overstated portfolio returns |\n\n: Standard Assumptions and Their Violations {#tbl-assumption-violations}\n\n### Adjusted Testing Procedure\n\nWe recommend the following adjustments to standard asset pricing tests when applied to Vietnamese data:\n\n1.  **Beta estimation**: Use Dimson ($K \\ge 1$) or Scholes-Williams betas, not OLS betas.\n\n2.  **Factor construction**: When forming size and value portfolios, apply liquidity filters before sorting. Consider excluding the smallest quintile of stocks by market capitalization, which is most affected by thin trading.\n\n3.  **Return aggregation**: Use monthly frequency. If daily analysis is necessary, include lagged market returns in the time-series regression.\n\n4.  **Robust inference**: Cluster standard errors by stock to account for persistent microstructure-induced serial correlation. Use Newey-West HAC standard errors with sufficient lags.\n\n5.  **Price limit adjustment**: For volatility analysis or risk measurement, consider the @chu2019forecasting approach of modeling the latent (uncensored) return distribution using truncated regression:\n\n$$\nr_{i,t}^* \\sim N(\\mu_i, \\sigma_i^2), \\quad r_{i,t}^{obs} = \\max(\\underline{L}, \\min(\\bar{L}, r_{i,t}^*))\n$$ {#eq-truncated}\n\nEstimate $\\mu_i$ and $\\sigma_i^2$ via maximum likelihood for the truncated normal.\n\n::: {#truncated-volatility .cell execution_count=22}\n``` {.python .cell-code}\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef truncated_normal_nll(params, returns, lower, upper):\n    \"\"\"Negative log-likelihood of truncated normal.\"\"\"\n    mu, log_sigma = params\n    sigma = np.exp(log_sigma)\n\n    # Interior observations\n    interior = (returns > lower) & (returns < upper)\n    ll_interior = norm.logpdf(returns[interior], mu, sigma)\n\n    # Lower censored\n    ll_lower = norm.logcdf(lower, mu, sigma)\n    n_lower = (returns <= lower).sum()\n\n    # Upper censored\n    ll_upper = np.log(1 - norm.cdf(upper, mu, sigma) + 1e-15)\n    n_upper = (returns >= upper).sum()\n\n    nll = -(ll_interior.sum() + n_lower * ll_lower + n_upper * ll_upper)\n    return nll\n\ndef estimate_true_volatility(returns, limit_band):\n    \"\"\"Estimate latent volatility correcting for price limit censoring.\"\"\"\n    result = minimize(\n        truncated_normal_nll,\n        x0=[returns.mean(), np.log(returns.std())],\n        args=(returns.values, -limit_band, limit_band),\n        method=\"Nelder-Mead\"\n    )\n    mu, log_sigma = result.x\n    return np.exp(log_sigma)\n```\n:::\n\n\n6.  **Sensitivity reporting**: Always report key results under alternative specifications: with and without liquidity filters, using OLS vs. Dimson betas, at daily vs. monthly frequency, and using observed vs. truncation-corrected volatility.\n\n## Summary\n\nThis chapter has established that Vietnamese equity markets exhibit microstructure characteristics that materially affect observed prices, returns, and risk measures. The key findings are:\n\n1.  **Price limits** censor daily returns, inducing positive autocorrelation, volatility spillover, and truncated distributions. The $\\pm$ 7% band on HOSE is particularly restrictive for volatile stocks.\n\n2.  **Thin trading and zero returns** afflict a substantial fraction of listed firms. Trading probabilities below 50% are common on HNX and UPCoM, generating non-synchronous trading bias that attenuates OLS beta estimates by 20-40%.\n\n3.  **Illiquidity** varies dramatically across the cross-section, with Amihud ratios spanning several orders of magnitude. Value-weighted portfolio returns are less contaminated than equal-weighted returns.\n\n4.  **The Dimson and Scholes-Williams beta corrections** effectively address non-synchronous trading bias and should be used as the default beta estimator for Vietnamese equities.\n\n5.  **Liquidity filters** should be applied before any asset pricing analysis, and results should be reported with and without these filters as a robustness check.\n\nIgnoring these frictions does not merely add noise to empirical results, it systematically biases estimates in predictable directions. The diagnostics and corrections presented in this chapter provide the foundation for credible empirical asset pricing in Vietnam.\n\n<!-- ## Exercises\n\n1.  **Intraday liquidity patterns**: Using intraday data, compute the average bid-ask spread and depth at 15-minute intervals throughout the trading day. Document the U-shaped intraday liquidity pattern and discuss how it relates to the theoretical predictions of @admati1988theory.\n\n2.  **Magnet effect test**: Test the @subrahmanyam1994circuit magnet effect hypothesis. Conditional on a stock hitting a price limit by the end of the day, does price acceleration toward the limit occur in the final 30 minutes of continuous trading? Compare the speed of price approach to the limit on limit-hit days versus non-limit-hit days.\n\n3.  **Liquidity-adjusted factor model**: Construct a tradeable liquidity factor (IML: Illiquid-Minus-Liquid) by sorting stocks into liquidity terciles using the Amihud ratio and forming a long-short portfolio. Augment the Fama-French three-factor model with this liquidity factor and test whether it improves the pricing of Vietnamese equities.\n\n4.  **Multi-day limit hits**: Identify episodes where the same stock hits the price limit on two or more consecutive days. How much cumulative price adjustment occurs over these multi-day limit episodes? Does the total adjustment exceed what would be expected under a one-day price change distribution?\n\n5.  **Non-synchronous trading and momentum**: The momentum effect may be partly an artifact of non-synchronous trading: past winners may simply be stocks with more recent prices. Re-examine the momentum premium after replacing OLS returns with Dimson-adjusted returns and after excluding stocks with trading probability below 50%.\n\n6.  **Cross-exchange comparison**: Exploit the difference in price limit bands across HOSE ($pm$ 7%), HNX ($pm$ 10%), and UPCoM ($pm$ 15%) to test the causal effect of price limit tightness on volatility spillover, zero-return frequency, and return autocorrelation. Use a difference-in-differences design if any exchange has changed its limit band during the sample period. -->\n\n",
    "supporting": [
      "03_market_microstructure_files/figure-pdf"
    ],
    "filters": []
  }
}