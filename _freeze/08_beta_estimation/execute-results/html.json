{
  "hash": "46af347a85e879ec99f2ed3e08d01a45",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Beta Estimation\nformat:\n  html:\n    toc: true\n    number-sections: true\njupyter: python3\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\nThis chapter introduces one of the most fundamental concepts in financial economics: the exposure of an individual stock to systematic market risk. According to the Capital Asset Pricing Model (CAPM) developed by @Sharpe1964, @Lintner1965, and @Mossin1966, cross-sectional variation in expected asset returns should be determined by the covariance between an asset's excess return and the excess return on the market portfolio. The regression coefficient that captures this relationship (commonly known as market beta) serves as the cornerstone of modern portfolio theory and remains widely used in practice for cost of capital estimation, performance attribution, and risk management.\n\nIn this chapter, we develop a complete framework for estimating market betas for Vietnamese stocks. We begin with a conceptual overview of the CAPM and its empirical implementation. We then demonstrate beta estimation using ordinary least squares regression, first for individual stocks and then scaled to the entire market using rolling-window estimation. To handle the computational demands of estimating betas for hundreds of stocks across many time periods, we introduce parallelization techniques that dramatically reduce processing time. Finally, we compare beta estimates derived from monthly versus daily returns and examine how betas vary across industries and over time in the Vietnamese market.\n\nThe chapter leverages several important computational concepts that extend beyond beta estimation itself. Rolling-window estimation is a technique applicable to any time-varying parameter, while parallelization provides a general solution for computationally intensive tasks that can be divided into independent subtasks.\n\n## Theoretical Foundation\n\n### The Capital Asset Pricing Model\n\nThe CAPM provides a theoretical framework linking expected returns to systematic risk. Under the model's assumptions—including mean-variance optimizing investors, homogeneous expectations, and frictionless markets—the expected excess return on any asset $i$ is proportional to its covariance with the market portfolio:\n\n$$\nE[r_i - r_f] = \\beta_i \\cdot E[r_m - r_f]\n$$\n\nwhere $r_i$ is the return on asset $i$, $r_f$ is the risk-free rate, $r_m$ is the return on the market portfolio, and $\\beta_i$ is defined as:\n\n$$\n\\beta_i = \\frac{\\text{Cov}(r_i, r_m)}{\\text{Var}(r_m)}\n$$\n\nThe market beta $\\beta_i$ measures the sensitivity of asset $i$'s returns to market movements. A beta greater than one indicates the asset amplifies market movements, while a beta less than one indicates dampened sensitivity. A beta of zero would imply no systematic risk exposure, leaving only idiosyncratic risk that can be diversified away.\n\n### Empirical Implementation\n\nIn practice, we estimate beta by regressing excess stock returns on excess market returns:\n\n$$\nr_{i,t} - r_{f,t} = \\alpha_i + \\beta_i(r_{m,t} - r_{f,t}) + \\varepsilon_{i,t}\n$$ {#eq-capm-regression}\n\nwhere $\\alpha_i$ represents abnormal return (Jensen's alpha), $\\beta_i$ is the market beta we seek to estimate, and $\\varepsilon_{i,t}$ is the idiosyncratic error term. Under the CAPM, $\\alpha_i$ should equal zero for all assets—any non-zero alpha represents a deviation from the model's predictions.\n\nSeveral practical considerations affect beta estimation:\n\n1.  **Estimation Window**: Longer windows provide more observations and thus more precise estimates, but may include outdated information if betas change over time. Common choices range from 36 to 60 months for monthly data.\n\n2.  **Return Frequency**: Monthly returns reduce noise but provide fewer observations. Daily returns offer more data points but may introduce microstructure effects and non-synchronous trading biases.\n\n3.  **Market Proxy**: The theoretical market portfolio includes all assets, but in practice we use a broad equity index. For Vietnam, we use the value-weighted market return constructed from our stock universe.\n\n4.  **Minimum Observations**: Requiring a minimum number of observations (e.g., 48 out of 60 months) helps avoid unreliable estimates from sparse data.\n\n## Setting Up the Environment\n\nWe begin by loading the necessary Python packages. The core packages handle data manipulation, statistical modeling, and database operations. We also import parallelization tools that will be essential when scaling our estimation to the full market.\n\n::: {#b604d6ab .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport sqlite3\nimport statsmodels.formula.api as smf\nfrom scipy.stats.mstats import winsorize\n\nfrom plotnine import *\nfrom mizani.formatters import percent_format, comma_format\nfrom joblib import Parallel, delayed, cpu_count\nfrom dateutil.relativedelta import relativedelta\n```\n:::\n\n\nWe connect to our SQLite database containing the processed Vietnamese financial data from previous chapters.\n\n::: {#2e692dac .cell execution_count=2}\n``` {.python .cell-code}\ntidy_finance = sqlite3.connect(database=\"data/tidy_finance_python.sqlite\")\n```\n:::\n\n\n## Loading and Preparing Data\n\n### Stock Returns Data\n\nWe load the monthly stock returns data prepared in the Datacore chapter. The data includes excess returns (returns minus the risk-free rate) for all Vietnamese listed stocks.\n\n::: {#6dec0062 .cell execution_count=3}\n``` {.python .cell-code}\nprices_monthly = pd.read_sql_query(\n    sql=\"\"\"\n        SELECT symbol, date, ret_excess \n        FROM prices_monthly\n    \"\"\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\n# Add year for merging with fundamentals\nprices_monthly[\"year\"] = prices_monthly[\"date\"].dt.year\n\nprint(f\"Loaded {len(prices_monthly):,} monthly observations\")\nprint(f\"Covering {prices_monthly['symbol'].nunique():,} unique stocks\")\nprint(f\"Date range: {prices_monthly['date'].min():%Y-%m} to {prices_monthly['date'].max():%Y-%m}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoaded 209,495 monthly observations\nCovering 1,837 unique stocks\nDate range: 2010-01 to 2025-05\n```\n:::\n:::\n\n\n::: {#3c8db2eb .cell execution_count=4}\n``` {.python .cell-code}\nprices_daily = pd.read_sql_query(\n    sql=\"\"\"\n        SELECT symbol, date, ret_excess \n        FROM prices_daily\n    \"\"\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n```\n:::\n\n\n### Company Information\n\nWe load company information to enable industry-level analysis of beta estimates.\n\n::: {#ad2bcc25 .cell execution_count=5}\n``` {.python .cell-code}\ncomp_vn = pd.read_sql_query(\n    sql=\"\"\"\n        SELECT symbol, datadate, icb_name_vi \n        FROM comp_vn\n    \"\"\",\n    con=tidy_finance,\n    parse_dates={\"datadate\"}\n)\n\n# Extract year for merging\ncomp_vn[\"year\"] = comp_vn[\"datadate\"].dt.year\n\nprint(f\"Company data: {comp_vn['symbol'].nunique():,} firms\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompany data: 1,502 firms\n```\n:::\n:::\n\n\n### Market Excess Returns\n\nFor the market portfolio proxy, we use the value-weighted market excess return. If you have constructed Fama-French factors in a previous chapter, load them here. Otherwise, we can construct a simple market return from our stock data.\n\n::: {#fae5d2ee .cell execution_count=6}\n``` {.python .cell-code}\n# Option 1: Load pre-computed market factor\nfactors_ff3_monthly = pd.read_sql_query(\n    sql=\"SELECT date, mkt_excess FROM factors_ff3_monthly\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\n# Option 2: Construct market return from stock data (if factors not available)\n# This computes the value-weighted average return across all stocks\ndef compute_market_return(prices_df):\n    \"\"\"\n    Compute value-weighted market return from individual stock returns.\n    \n    Parameters\n    ----------\n    prices_df : pd.DataFrame\n        Stock returns with mktcap_lag for weighting\n        \n    Returns\n    -------\n    pd.DataFrame\n        Monthly market excess returns\n    \"\"\"\n    market_return = (prices_df\n        .groupby(\"date\")\n        .apply(lambda x: np.average(x[\"ret_excess\"], weights=x[\"mktcap_lag\"]))\n        .reset_index(name=\"mkt_excess\")\n    )\n    return market_return\n```\n:::\n\n\n### Merging Datasets\n\nWe combine the stock returns with market returns and company information to create our estimation dataset.\n\n::: {#dbd9891e .cell execution_count=7}\n``` {.python .cell-code}\n# Merge stock returns with market returns\nprices_monthly = prices_monthly.merge(\n    factors_ff3_monthly, \n    on=\"date\", \n    how=\"left\"\n)\n\n# Merge with company information for industry classification\nprices_monthly = prices_monthly.merge(\n    comp_vn[[\"symbol\", \"year\", \"icb_name_vi\"]], \n    on=[\"symbol\", \"year\"], \n    how=\"left\"\n)\n\n# Remove observations with missing data\nprices_monthly = prices_monthly.dropna(subset=[\"ret_excess\", \"mkt_excess\"])\n\nprint(f\"Final estimation sample: {len(prices_monthly):,} observations\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFinal estimation sample: 169,983 observations\n```\n:::\n:::\n\n\n### Handling Outliers\n\nExtreme returns can unduly influence regression estimates. We apply winsorization to limit the impact of outliers while preserving the general distribution of returns. Winsorization at the 1% level replaces values below the 1st percentile with the 1st percentile value, and values above the 99th percentile with the 99th percentile value.\n\n::: {#5828fe36 .cell execution_count=8}\n``` {.python .cell-code}\ndef winsorize_returns(df, columns, limits=(0.01, 0.01)):\n    \"\"\"\n    Apply winsorization to return columns to limit outlier influence.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame containing return columns\n    columns : list\n        Column names to winsorize\n    limits : tuple\n        Lower and upper percentile limits for winsorization\n        \n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with winsorized columns\n    \"\"\"\n    df = df.copy()\n    for col in columns:\n        df[col] = winsorize(df[col], limits=limits)\n    return df\n\nprices_monthly = winsorize_returns(\n    prices_monthly, \n    columns=[\"ret_excess\", \"mkt_excess\"],\n    limits=(0.01, 0.01)\n)\n\nprint(\"Return distributions after winsorization:\")\nprint(prices_monthly[[\"ret_excess\", \"mkt_excess\"]].describe().round(4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReturn distributions after winsorization:\n        ret_excess   mkt_excess\ncount  169983.0000  169983.0000\nmean        0.0011      -0.0102\nstd         0.1548       0.0579\nmin        -0.4078      -0.1794\n25%        -0.0700      -0.0384\n50%        -0.0033      -0.0084\n75%         0.0531       0.0219\nmax         0.6117       0.1221\n```\n:::\n:::\n\n\n## Estimating Beta for Individual Stocks\n\n### Single Stock Example\n\nBefore scaling to the full market, we demonstrate beta estimation for a single well-known Vietnamese stock. We use Vingroup (VIC), one of the largest conglomerates in Vietnam with significant exposure to real estate, retail, and automotive sectors.\n\n::: {#484778d9 .cell execution_count=9}\n``` {.python .cell-code}\n# Filter data for Vingroup\nvic_data = prices_monthly.query(\"symbol == 'VIC'\").copy()\n\nprint(f\"VIC observations: {len(vic_data)}\")\nprint(f\"Date range: {vic_data['date'].min():%Y-%m} to {vic_data['date'].max():%Y-%m}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVIC observations: 150\nDate range: 2011-07 to 2023-12\n```\n:::\n:::\n\n\nWe estimate the CAPM regression using ordinary least squares via the `statsmodels` package. The formula interface provides a convenient way to specify regression models.\n\n::: {#ccd89e98 .cell execution_count=10}\n``` {.python .cell-code}\n# Estimate CAPM for Vingroup\nmodel_vic = smf.ols(\n    formula=\"ret_excess ~ mkt_excess\",\n    data=vic_data\n).fit()\n\n# Display regression results\nprint(model_vic.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             ret_excess   R-squared:                       0.153\nModel:                            OLS   Adj. R-squared:                  0.147\nMethod:                 Least Squares   F-statistic:                     26.67\nDate:                Wed, 04 Feb 2026   Prob (F-statistic):           7.66e-07\nTime:                        10:19:28   Log-Likelihood:                 131.96\nNo. Observations:                 150   AIC:                            -259.9\nDf Residuals:                     148   BIC:                            -253.9\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -0.0075      0.008     -0.895      0.372      -0.024       0.009\nmkt_excess     0.7503      0.145      5.164      0.000       0.463       1.037\n==============================================================================\nOmnibus:                       39.111   Durbin-Watson:                   2.039\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              107.620\nSkew:                          -1.015   Prob(JB):                     4.27e-24\nKurtosis:                       6.619   Cond. No.                         17.6\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\nThe regression output provides several important pieces of information:\n\n-   **Beta (mkt_excess coefficient)**: The estimated market sensitivity. A beta above 1 indicates VIC amplifies market movements.\n-   **Alpha (Intercept)**: The abnormal return not explained by market exposure. Under CAPM, this should be zero.\n-   **R-squared**: The proportion of return variation explained by market movements.\n-   **t-statistics**: Test whether coefficients differ significantly from zero.\n\n::: {#4fa71df5 .cell execution_count=11}\n``` {.python .cell-code}\n# Extract key estimates\ncoefficients = model_vic.summary2().tables[1]\n\nprint(\"\\nKey estimates for Vingroup (VIC):\")\nprint(f\"  Beta:  {coefficients.loc['mkt_excess', 'Coef.']:.3f}\")\nprint(f\"  Alpha: {coefficients.loc['Intercept', 'Coef.']:.4f}\")\nprint(f\"  R²:    {model_vic.rsquared:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nKey estimates for Vingroup (VIC):\n  Beta:  0.750\n  Alpha: -0.0075\n  R²:    0.153\n```\n:::\n:::\n\n\n### CAPM Estimation Function\n\nWe create a reusable function that estimates the CAPM and returns results in a standardized format. The function includes a minimum observations requirement to avoid unreliable estimates from sparse data.\n\n::: {#e17c5bf2 .cell execution_count=12}\n``` {.python .cell-code}\ndef estimate_capm(data, min_obs=48):\n    \"\"\"\n    Estimate CAPM regression and return coefficients.\n    \n    This function regresses excess stock returns on excess market returns\n    and extracts the coefficient estimates along with t-statistics.\n    \n    Parameters\n    ----------\n    data : pd.DataFrame\n        DataFrame with 'ret_excess' and 'mkt_excess' columns\n    min_obs : int\n        Minimum number of observations required for estimation\n        \n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with coefficient estimates and t-statistics,\n        or empty DataFrame if insufficient observations\n    \"\"\"\n    if len(data) < min_obs:\n        return pd.DataFrame()\n    \n    try:\n        # Estimate OLS regression\n        model = smf.ols(\n            formula=\"ret_excess ~ mkt_excess\", \n            data=data\n        ).fit()\n        \n        # Extract coefficient table\n        coef_table = model.summary2().tables[1]\n        \n        # Format results\n        results = pd.DataFrame({\n            \"coefficient\": [\"alpha\", \"beta\"],\n            \"estimate\": [\n                coef_table.loc[\"Intercept\", \"Coef.\"],\n                coef_table.loc[\"mkt_excess\", \"Coef.\"]\n            ],\n            \"t_statistic\": [\n                coef_table.loc[\"Intercept\", \"t\"],\n                coef_table.loc[\"mkt_excess\", \"t\"]\n            ],\n            \"r_squared\": model.rsquared\n        })\n        \n        return results\n        \n    except Exception as e:\n        # Return empty DataFrame if estimation fails\n        return pd.DataFrame()\n```\n:::\n\n\n## Rolling-Window Estimation\n\n### Motivation for Rolling Windows\n\nStock betas are not constant over time. A company's business mix, leverage, and operating environment evolve, causing its systematic risk exposure to change. To capture this time variation, we use rolling-window estimation: at each point in time, we estimate beta using only data from a fixed lookback period (e.g., the past 60 months).\n\nRolling-window estimation involves a trade-off:\n\n-   **Longer windows** provide more observations and thus more precise estimates, but may include stale information.\n-   **Shorter windows** are more responsive to changes but produce noisier estimates.\n\nA common choice in academic research is 60 months (5 years) of monthly data, requiring at least 48 valid observations for estimation.\n\n### Rolling Window Implementation\n\nThe following function implements rolling-window CAPM estimation. For each month in the sample, it looks back over the specified window and estimates beta using all available data within that window.\n\n::: {#cb5a7477 .cell execution_count=13}\n``` {.python .cell-code}\ndef roll_capm_estimation(data, look_back=60, min_obs=48):\n    \"\"\"\n    Perform rolling-window CAPM estimation.\n    \n    This function slides a window across time, estimating the CAPM\n    regression at each point using the most recent 'look_back' months\n    of data.\n    \n    Parameters\n    ----------\n    data : pd.DataFrame\n        DataFrame with 'date', 'ret_excess', and 'mkt_excess' columns\n    look_back : int\n        Number of months in the estimation window\n    min_obs : int\n        Minimum observations required within each window\n        \n    Returns\n    -------\n    pd.DataFrame\n        Time series of coefficient estimates with dates\n    \"\"\"\n    # Ensure data is sorted by date\n    data = data.sort_values(\"date\").copy()\n    \n    # Get unique dates\n    dates = data[\"date\"].drop_duplicates().sort_values()\n    \n    # Container for results\n    results = []\n    \n    # Slide window across dates\n    for i in range(look_back - 1, len(dates)):\n        # Define window boundaries\n        end_date = dates.iloc[i]\n        start_date = end_date - relativedelta(months=look_back - 1)\n        \n        # Extract data within window\n        window_data = data.query(\"date >= @start_date and date <= @end_date\")\n        \n        # Estimate CAPM for this window\n        window_results = estimate_capm(window_data, min_obs=min_obs)\n        \n        if not window_results.empty:\n            window_results[\"date\"] = end_date\n            results.append(window_results)\n    \n    # Combine all results\n    if results:\n        return pd.concat(results, ignore_index=True)\n    else:\n        return pd.DataFrame()\n```\n:::\n\n\n### Example: Rolling Betas for Selected Stocks\n\nWe demonstrate rolling-window estimation for several well-known Vietnamese stocks spanning different industries.\n\n::: {#dbafab81 .cell execution_count=14}\n``` {.python .cell-code}\n# Define example stocks\nexamples = pd.DataFrame({\n    \"symbol\": [\"FPT\", \"VNM\", \"VIC\", \"HPG\", \"VCB\"],\n    \"company\": [\n        \"FPT Corporation\",      # Technology\n        \"Vinamilk\",             # Consumer goods\n        \"Vingroup\",             # Real estate/conglomerate\n        \"Hoa Phat Group\",       # Steel/materials\n        \"Vietcombank\"           # Banking\n    ]\n})\n\n# Check data availability for each example\ndata_availability = (prices_monthly\n    .query(\"symbol in @examples['symbol']\")\n    .groupby(\"symbol\")\n    .agg(\n        n_obs=(\"date\", \"count\"),\n        first_date=(\"date\", \"min\"),\n        last_date=(\"date\", \"max\")\n    )\n    .reset_index()\n)\n\nprint(\"Data availability for example stocks:\")\nprint(data_availability)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData availability for example stocks:\n  symbol  n_obs first_date  last_date\n0    FPT    150 2011-07-31 2023-12-31\n1    HPG    150 2011-07-31 2023-12-31\n2    VCB    150 2011-07-31 2023-12-31\n3    VIC    150 2011-07-31 2023-12-31\n4    VNM    150 2011-07-31 2023-12-31\n```\n:::\n:::\n\n\n::: {#a7c126ff .cell execution_count=15}\n``` {.python .cell-code}\n# Estimate rolling betas for example stocks\nexample_data = prices_monthly.query(\"symbol in @examples['symbol']\")\n\ncapm_examples = (example_data\n    .groupby(\"symbol\", group_keys=True)\n    .apply(lambda x: roll_capm_estimation(x), include_groups=False)\n    .reset_index()\n    .drop(columns=\"level_1\", errors=\"ignore\")\n)\n\n# Filter to beta estimates only\nbeta_examples = (capm_examples\n    .query(\"coefficient == 'beta'\")\n    .merge(examples, on=\"symbol\")\n)\n\nprint(f\"Rolling beta estimates: {len(beta_examples):,} observations\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRolling beta estimates: 455 observations\n```\n:::\n:::\n\n\n### Visualizing Rolling Betas\n\n@fig-rolling-betas displays the time series of beta estimates for our example stocks. The figure reveals how systematic risk exposure evolves differently across industries.\n\n::: {#cell-fig-rolling-betas .cell execution_count=16}\n``` {.python .cell-code}\nrolling_beta_figure = (\n    ggplot(\n        beta_examples,\n        aes(x=\"date\", y=\"estimate\", color=\"company\")\n    )\n    + geom_line(size=0.8)\n    + geom_hline(yintercept=1, linetype=\"dashed\", color=\"gray\", alpha=0.7)\n    + labs(\n        x=\"\",\n        y=\"Beta\",\n        color=\"\",\n        title=\"Rolling Beta Estimates (60-Month Window)\"\n    )\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + theme_minimal()\n    + theme(legend_position=\"bottom\")\n)\nrolling_beta_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Monthly rolling beta estimates for selected Vietnamese stocks using a 60-month estimation window. Different industries exhibit distinct patterns of market sensitivity over time.](08_beta_estimation_files/figure-html/fig-rolling-betas-output-1.png){#fig-rolling-betas width=672 height=480 fig-align='center' fig-alt='Line chart showing time series of beta estimates for five Vietnamese stocks from different industries.'}\n:::\n:::\n\n\nSeveral patterns emerge from the figure:\n\n1.  **Industry differences**: Technology and banking stocks may exhibit different beta patterns than real estate or consumer goods companies.\n\n2.  **Time variation**: Betas are not constant. They respond to changes in business conditions, leverage, and market regimes.\n\n3.  **Crisis periods**: Market stress periods (e.g., 2008 financial crisis, 2020 COVID-19) often see beta estimates change as correlations across stocks increase.\n\n## Parallelized Estimation for the Full Market\n\n### The Computational Challenge\n\nEstimating rolling betas for all stocks in our database is computationally intensive. With hundreds of stocks, each requiring rolling estimation across many time periods, sequential processing would take considerable time. Fortunately, beta estimation for different stocks is independent (i.e., the estimate for stock A does not depend on the estimate for stock B). This independence makes the problem ideal for parallelization.\n\n### Setting Up Parallel Processing\n\nWe use the `joblib` library to distribute computation across multiple CPU cores. The `Parallel` class manages worker processes, while `delayed` wraps function calls for deferred execution.\n\n::: {#39cec92a .cell execution_count=17}\n``` {.python .cell-code}\n# Determine available cores (reserve one for system operations)\nn_cores = max(1, cpu_count() - 1)\nprint(f\"Available cores for parallel processing: {n_cores}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAvailable cores for parallel processing: 3\n```\n:::\n:::\n\n\n### Parallel Beta Estimation\n\nThe following code estimates rolling betas for all stocks in parallel. Each stock is processed independently by a separate worker.\n\n::: {#3f43fea5 .cell execution_count=18}\n``` {.python .cell-code}\ndef estimate_all_betas_parallel(data, n_cores, look_back=60, min_obs=48):\n    \"\"\"\n    Estimate rolling betas for all stocks using parallel processing.\n    \n    Parameters\n    ----------\n    data : pd.DataFrame\n        Full dataset with all stocks\n    n_cores : int\n        Number of CPU cores to use\n    look_back : int\n        Months in estimation window\n    min_obs : int\n        Minimum observations required\n        \n    Returns\n    -------\n    pd.DataFrame\n        Beta estimates for all stocks and dates\n    \"\"\"\n    # Group data by stock\n    grouped = data.groupby(\"symbol\", group_keys=False)\n    \n    # Define worker function\n    def process_stock(name, group):\n        result = roll_capm_estimation(group, look_back=look_back, min_obs=min_obs)\n        if not result.empty:\n            result[\"symbol\"] = name\n        return result\n    \n    # Execute in parallel\n    results = Parallel(n_jobs=n_cores, verbose=1)(\n        delayed(process_stock)(name, group) \n        for name, group in grouped\n    )\n    \n    # Combine results\n    results = [r for r in results if not r.empty]\n    if results:\n        return pd.concat(results, ignore_index=True)\n    else:\n        return pd.DataFrame()\n```\n:::\n\n\n::: {#1015a664 .cell execution_count=19}\n``` {.python .cell-code}\n# Estimate betas for all stocks\nprint(\"Estimating rolling betas for all stocks...\")\ncapm_monthly = estimate_all_betas_parallel(\n    prices_monthly, \n    n_cores=n_cores,\n    look_back=60,\n    min_obs=48\n)\n\nprint(f\"\\nCompleted: {len(capm_monthly):,} coefficient estimates\")\nprint(f\"Unique stocks: {capm_monthly['symbol'].nunique():,}\")\n```\n:::\n\n\n### Storing Results\n\nWe save the CAPM estimates to our database for use in subsequent chapters.\n\n::: {#1cf396d7 .cell execution_count=20}\n``` {.python .cell-code}\ncapm_monthly.to_sql(\n    name=\"capm_monthly\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\n\nprint(\"CAPM estimates saved to database.\")\n```\n:::\n\n\nFor subsequent analysis, we load the pre-computed estimates:\n\n::: {#9dd1c9d3 .cell execution_count=21}\n``` {.python .cell-code}\ncapm_monthly = pd.read_sql_query(\n    sql=\"SELECT * FROM capm_monthly\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\nprint(f\"Loaded {len(capm_monthly):,} CAPM estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoaded 161,580 CAPM estimates\n```\n:::\n:::\n\n\n## Beta Estimation Using Daily Returns\n\nWhile monthly returns are standard in academic research, some applications benefit from higher-frequency data:\n\n-   **Shorter estimation windows**: Daily data allows meaningful estimation over shorter periods (e.g., 3 months rather than 5 years).\n-   **More responsive estimates**: Daily betas capture changes more quickly.\n-   **Event studies**: High-frequency betas are useful for analyzing market reactions to specific events.\n\nHowever, daily data introduces additional challenges:\n\n-   **Microstructure noise**: Bid-ask bounce and other trading frictions add noise to returns.\n-   **Non-synchronous trading**: Less liquid stocks may not trade every day, biasing beta estimates downward.\n-   **Computational burden**: Daily data is roughly 21 times larger than monthly data.\n\n### Batch Processing for Daily Data\n\nGiven the size of daily data, we process stocks in batches to manage memory constraints. This approach loads and processes a subset of stocks, saves results, and proceeds to the next batch.\n\n::: {#93d0d5e5 .cell execution_count=22}\n``` {.python .cell-code}\ndef compute_market_return_daily(tidy_finance):\n    \"\"\"\n    Compute daily value-weighted market excess return from stock data.\n    \"\"\"\n    # Load daily prices with market cap for weighting\n    prices_daily_full = pd.read_sql_query(\n        sql=\"\"\"\n            SELECT p.symbol, p.date, p.ret_excess, m.mktcap_lag\n            FROM prices_daily p\n            LEFT JOIN prices_monthly m ON p.symbol = m.symbol \n                AND strftime('%Y-%m', p.date) = strftime('%Y-%m', m.date)\n        \"\"\",\n        con=tidy_finance,\n        parse_dates={\"date\"}\n    )\n    \n    # Compute value-weighted market return each day\n    mkt_daily = (prices_daily_full\n        .dropna(subset=[\"ret_excess\", \"mktcap_lag\"])\n        .groupby(\"date\")\n        .apply(lambda x: np.average(x[\"ret_excess\"], weights=x[\"mktcap_lag\"]))\n        .reset_index(name=\"mkt_excess\")\n    )\n    \n    return mkt_daily\n\n\ndef roll_capm_estimation_daily(data, look_back_days=1260, min_obs=1000):\n    \"\"\"\n    Perform rolling-window CAPM estimation using daily data.\n    \n    Parameters\n    ----------\n    data : pd.DataFrame\n        DataFrame with 'date', 'ret_excess', and 'mkt_excess' columns\n    look_back_days : int\n        Number of trading days in the estimation window\n    min_obs : int\n        Minimum daily observations required within each window\n        \n    Returns\n    -------\n    pd.DataFrame\n        Time series of coefficient estimates with dates\n    \"\"\"\n    data = data.sort_values(\"date\").copy()\n    dates = data[\"date\"].drop_duplicates().sort_values().reset_index(drop=True)\n    \n    results = []\n    \n    for i in range(look_back_days - 1, len(dates)):\n        end_date = dates.iloc[i]\n        start_idx = max(0, i - look_back_days + 1)\n        start_date = dates.iloc[start_idx]\n        \n        window_data = data.query(\"date >= @start_date and date <= @end_date\")\n        window_results = estimate_capm(window_data, min_obs=min_obs)\n        \n        if not window_results.empty:\n            window_results[\"date\"] = end_date\n            results.append(window_results)\n    \n    if results:\n        return pd.concat(results, ignore_index=True)\n    else:\n        return pd.DataFrame()\n\n\ndef estimate_daily_betas_batch(symbols, tidy_finance, n_cores, batch_size=500, \n                                look_back_days=1260, min_obs=1000):\n    \"\"\"\n    Estimate rolling betas from daily data using batch processing.\n    \"\"\"\n    # First, compute or load market return\n    print(\"Computing daily market excess returns...\")\n    mkt_daily = compute_market_return_daily(tidy_finance)\n    print(f\"Market returns: {len(mkt_daily)} days\")\n    \n    n_batches = int(np.ceil(len(symbols) / batch_size))\n    all_results = []\n    \n    for j in range(n_batches):\n        batch_start = j * batch_size\n        batch_end = min((j + 1) * batch_size, len(symbols))\n        batch_symbols = symbols[batch_start:batch_end]\n        \n        symbol_list = \", \".join(f\"'{s}'\" for s in batch_symbols)\n        \n        query = f\"\"\"\n            SELECT symbol, date, ret_excess\n            FROM prices_daily\n            WHERE symbol IN ({symbol_list})\n        \"\"\"\n        \n        prices_daily_batch = pd.read_sql_query(\n            sql=query,\n            con=tidy_finance,\n            parse_dates={\"date\"}\n        )\n        \n        # Merge with market excess return\n        prices_daily_batch = prices_daily_batch.merge(\n            mkt_daily, \n            on=\"date\", \n            how=\"inner\"\n        )\n        \n        # Group by symbol and estimate betas\n        grouped = prices_daily_batch.groupby(\"symbol\", group_keys=False)\n        \n        # Parallel estimation\n        batch_results = Parallel(n_jobs=n_cores)(\n            delayed(lambda name, group: \n                roll_capm_estimation_daily(group, look_back_days=look_back_days, min_obs=min_obs)\n                .assign(symbol=name)\n            )(name, group)\n            for name, group in grouped\n        )\n        \n        batch_results = [r for r in batch_results if r is not None and not r.empty]\n        \n        if batch_results:\n            all_results.append(pd.concat(batch_results, ignore_index=True))\n        \n        print(f\"Batch {j+1}/{n_batches} complete\")\n    \n    if all_results:\n        return pd.concat(all_results, ignore_index=True)\n    else:\n        return pd.DataFrame()\n```\n:::\n\n\n::: {#6a09686c .cell execution_count=23}\n``` {.python .cell-code}\nsymbols = prices_monthly[\"symbol\"].unique().tolist()\n\ncapm_daily = estimate_daily_betas_batch(\n    symbols=symbols,\n    tidy_finance=tidy_finance,\n    n_cores=n_cores,\n    batch_size=500,\n    look_back_days=1260,  # ~5 years of trading days\n    min_obs=1000\n)\n\nprint(f\"Daily beta estimates: {len(capm_daily):,}\")\n```\n:::\n\n\n::: {#bafd585b .cell execution_count=24}\n``` {.python .cell-code}\ncapm_daily.to_sql(\n    name=\"capm_daily\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\n\nprint(\"CAPM estimates saved to database.\")\n```\n:::\n\n\nFor subsequent analysis, we load the pre-computed estimates:\n\n::: {#21713135 .cell execution_count=25}\n``` {.python .cell-code}\ncapm_daily = pd.read_sql_query(\n    sql=\"SELECT * FROM capm_daily\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n\nprint(f\"Loaded {len(capm_daily):,} CAPM estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoaded 3,394,490 CAPM estimates\n```\n:::\n:::\n\n\n## Analyzing Beta Estimates\n\n### Extracting Beta Estimates\n\nWe extract the beta coefficient estimates from our CAPM results for analysis.\n\n::: {#4c1844af .cell execution_count=26}\n``` {.python .cell-code}\n# Extract monthly betas\nbeta_monthly = (capm_monthly\n    .query(\"coefficient == 'beta'\")\n    .rename(columns={\"estimate\": \"beta\"})\n    [[\"symbol\", \"date\", \"beta\"]]\n    .assign(frequency=\"monthly\")\n)\n\n# Save to database\nbeta_monthly.to_sql(\n    name=\"beta_monthly\",\n    con=tidy_finance,\n    if_exists=\"replace\",\n    index=False\n)\n\nprint(f\"Monthly betas: {len(beta_monthly):,} observations\")\nprint(f\"Unique stocks: {beta_monthly['symbol'].nunique():,}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMonthly betas: 80,790 observations\nUnique stocks: 1,383\n```\n:::\n:::\n\n\n::: {#a3381455 .cell execution_count=27}\n``` {.python .cell-code}\n# Load pre-computed betas\nbeta_monthly = pd.read_sql_query(\n    sql=\"SELECT * FROM beta_monthly\",\n    con=tidy_finance,\n    parse_dates={\"date\"}\n)\n```\n:::\n\n\n### Summary Statistics\n\nWe examine the distribution of beta estimates to verify their reasonableness.\n\n::: {#2d9a0259 .cell execution_count=28}\n``` {.python .cell-code}\nprint(\"Beta Summary Statistics:\")\nprint(beta_monthly[\"beta\"].describe().round(3))\n\n# Additional diagnostics\nprint(f\"\\nStocks with negative average beta: {(beta_monthly.groupby('symbol')['beta'].mean() < 0).sum()}\")\nprint(f\"Stocks with beta > 2: {(beta_monthly.groupby('symbol')['beta'].mean() > 2).sum()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBeta Summary Statistics:\ncount    80790.000\nmean         0.501\nstd          0.539\nmin         -1.345\n25%          0.130\n50%          0.447\n75%          0.832\nmax          2.678\nName: beta, dtype: float64\n\nStocks with negative average beta: 177\nStocks with beta > 2: 5\n```\n:::\n:::\n\n\n### Beta Distribution Across Industries\n\nDifferent industries have different exposures to systematic market risk based on their business models, operating leverage, and financial leverage. @fig-beta-by-industry shows the distribution of firm-level average betas across Vietnamese industries.\n\n::: {#4dd162f0 .cell execution_count=29}\n``` {.python .cell-code}\n# Merge betas with industry information\nbeta_with_industry = (beta_monthly\n    .merge(\n        prices_monthly[[\"symbol\", \"date\", \"icb_name_vi\"]].drop_duplicates(),\n        on=[\"symbol\", \"date\"],\n        how=\"left\"\n    )\n    .dropna(subset=[\"icb_name_vi\"])\n)\n\n# Compute firm-level average beta by industry\nbeta_by_industry = (beta_with_industry\n    .groupby([\"icb_name_vi\", \"symbol\"])[\"beta\"]\n    .mean()\n    .reset_index()\n)\n\n# Order industries by median beta\nindustry_order = (beta_by_industry\n    .groupby(\"icb_name_vi\")[\"beta\"]\n    .median()\n    .sort_values()\n    .index.tolist()\n)\n\n# Select top 10 industries by number of firms for clearer visualization\ntop_industries = (beta_by_industry\n    .groupby(\"icb_name_vi\")\n    .size()\n    .nlargest(10)\n    .index.tolist()\n)\n\nbeta_by_industry_filtered = beta_by_industry.query(\"icb_name_vi in @top_industries\")\n```\n:::\n\n\n::: {#cell-fig-beta-by-industry .cell execution_count=30}\n``` {.python .cell-code}\nbeta_industry_figure = (\n    ggplot(\n        beta_by_industry_filtered,\n        aes(x=\"icb_name_vi\", y=\"beta\")\n    )\n    + geom_boxplot(fill=\"steelblue\", alpha=0.7)\n    + geom_hline(yintercept=1, linetype=\"dashed\", color=\"red\", alpha=0.7)\n    + coord_flip()\n    + labs(\n        x=\"\",\n        y=\"Beta\",\n        title=\"Beta Distribution by Industry\"\n    )\n    + theme_minimal()\n)\nbeta_industry_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Distribution of firm-level average betas across Vietnamese industries. Box plots show the median, interquartile range, and outliers for each industry.](08_beta_estimation_files/figure-html/fig-beta-by-industry-output-1.png){#fig-beta-by-industry width=672 height=480 fig-alt='Box plots showing beta distributions by industry, ordered by median beta.'}\n:::\n:::\n\n\n### Time Variation in Cross-Sectional Beta Distribution\n\nBetas vary not only across stocks but also over time. @fig-beta-quantiles shows how the cross-sectional distribution of betas has evolved in the Vietnamese market.\n\n::: {#cell-fig-beta-quantiles .cell execution_count=31}\n``` {.python .cell-code}\n# Compute monthly quantiles\nbeta_quantiles = (beta_monthly\n    .groupby(\"date\")[\"beta\"]\n    .quantile(q=np.arange(0.1, 1.0, 0.1))\n    .reset_index()\n    .rename(columns={\"level_1\": \"quantile\"})\n    .assign(quantile=lambda x: (x[\"quantile\"] * 100).astype(int).astype(str) + \"%\")\n)\n\nbeta_quantiles_figure = (\n    ggplot(\n        beta_quantiles,\n        aes(x=\"date\", y=\"beta\", color=\"quantile\")\n    )\n    + geom_line(alpha=0.8)\n    + geom_hline(yintercept=1, linetype=\"dashed\", color=\"gray\")\n    + labs(\n        x=\"\",\n        y=\"Beta\",\n        color=\"Quantile\",\n        title=\"Cross-Sectional Distribution of Betas Over Time\"\n    )\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + theme_minimal()\n)\nbeta_quantiles_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Monthly quantiles of beta estimates over time. Each line represents a decile of the cross-sectional beta distribution.](08_beta_estimation_files/figure-html/fig-beta-quantiles-output-1.png){#fig-beta-quantiles width=672 height=480 fig-alt='Line chart showing time series of beta deciles, illustrating how the distribution of betas has changed over time.'}\n:::\n:::\n\n\nThe figure reveals several interesting patterns:\n\n1.  **Level shifts**: The entire distribution of betas can shift over time, reflecting changes in market-wide correlation.\n\n2.  **Dispersion changes**: During market stress, the spread between high and low beta stocks may change as correlations move.\n\n3.  **Trends**: Some periods show trending behavior in betas, possibly reflecting structural changes in the economy.\n\n### Coverage Analysis\n\nWe verify that our estimation procedure produces reasonable coverage across the sample. @fig-beta-coverage shows the fraction of stocks with available beta estimates over time.\n\n::: {#cell-fig-beta-coverage .cell execution_count=32}\n``` {.python .cell-code}\n# Count stocks with and without betas\ncoverage = (prices_monthly\n    .groupby(\"date\")[\"symbol\"]\n    .nunique()\n    .reset_index(name=\"total_stocks\")\n    .merge(\n        beta_monthly.groupby(\"date\")[\"symbol\"].nunique().reset_index(name=\"with_beta\"),\n        on=\"date\",\n        how=\"left\"\n    )\n    .fillna(0)\n    .assign(coverage=lambda x: x[\"with_beta\"] / x[\"total_stocks\"])\n)\n\ncoverage_figure = (\n    ggplot(coverage, aes(x=\"date\", y=\"coverage\"))\n    + geom_line(color=\"steelblue\", size=1)\n    + labs(\n        x=\"\",\n        y=\"Share with Beta Estimate\",\n        title=\"Beta Estimation Coverage Over Time\"\n    )\n    + scale_y_continuous(labels=percent_format(), limits=(0, 1))\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + theme_minimal()\n)\ncoverage_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Share of stocks with available beta estimates over time. Coverage increases as more stocks accumulate sufficient return history.](08_beta_estimation_files/figure-html/fig-beta-coverage-output-1.png){#fig-beta-coverage width=672 height=480 fig-alt='Line chart showing the percentage of stocks with beta estimates available each month.'}\n:::\n:::\n\n\nCoverage is lower in early years because stocks need sufficient return history (at least 48 months) before their betas can be estimated. As the market matures and stocks accumulate longer histories, coverage approaches 100%.\n\n## Comparing Monthly and Daily Beta Estimates\n\nWhen both monthly and daily beta estimates are available, we can compare them to understand how estimation frequency affects results.\n\n::: {#95ea3860 .cell execution_count=33}\n``` {.python .cell-code}\n# Combine monthly and daily estimates\nbeta_daily = (capm_daily\n    .query(\"coefficient == 'beta'\")\n    .rename(columns={\"estimate\": \"beta\"})\n    [[\"symbol\", \"date\", \"beta\"]]\n    .assign(frequency=\"daily\")\n)\n\nbeta_combined = pd.concat([beta_monthly, beta_daily], ignore_index=True)\n```\n:::\n\n\n::: {#cell-fig-beta-comparison .cell execution_count=34}\n``` {.python .cell-code}\n# Filter to example stocks\nbeta_comparison = (beta_combined\n    .merge(examples, on=\"symbol\")\n    .query(\"symbol in ['VIC', 'FPT']\")  # Select two for clarity\n)\n\ncomparison_figure = (\n    ggplot(\n        beta_comparison,\n        aes(x=\"date\", y=\"beta\", color=\"frequency\", linetype=\"frequency\")\n    )\n    + geom_line(size=0.8)\n    + facet_wrap(\"~company\", ncol=1)\n    + labs(\n        x=\"\",\n        y=\"Beta\",\n        color=\"Data Frequency\",\n        linetype=\"Data Frequency\",\n        title=\"Monthly vs Daily Beta Estimates\"\n    )\n    + scale_x_datetime(date_breaks=\"2 years\", date_labels=\"%Y\")\n    + theme_minimal()\n    + theme(legend_position=\"bottom\")\n)\ncomparison_figure.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison of beta estimates using monthly versus daily returns for selected stocks. Daily estimates are smoother due to more observations per estimation window.](08_beta_estimation_files/figure-html/fig-beta-comparison-output-1.png){#fig-beta-comparison width=672 height=480 fig-alt='Line chart comparing monthly and daily beta estimates over time for example stocks.'}\n:::\n:::\n\n\nThe comparison reveals that daily-based estimates are generally smoother due to the larger number of observations in each window. However, the level and trend of estimates are similar across frequencies, providing validation that both approaches capture the same underlying systematic risk exposure.\n\n::: {#31f7ea57 .cell execution_count=35}\n``` {.python .cell-code}\n# Correlation between monthly and daily estimates\ncorrelation_data = (beta_combined\n    .pivot_table(index=[\"symbol\", \"date\"], columns=\"frequency\", values=\"beta\")\n    .dropna()\n)\n\nprint(f\"Correlation between monthly and daily betas: {correlation_data.corr().iloc[0,1]:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorrelation between monthly and daily betas: 0.745\n```\n:::\n:::\n\n\n| Factor | Effect |\n|------------------------------------|------------------------------------|\n| Non-synchronous trading | Daily betas can be biased downward for illiquid stocks |\n| Microstructure noise | Bid-ask bounce adds noise to daily estimates |\n| Different effective windows | Same calendar period but \\~20x more observations for daily |\n| Mean reversion speed | Daily captures faster-moving risk dynamics |\n\n: Theoretical Reasons for Imperfect Correlation {#tbl-imperfect-cor}\n\n@tbl-imperfect-cor shows several reasons why we might observe imperfect correlation.\n\n## Key Takeaways\n\n1.  **CAPM beta** measures a stock's sensitivity to systematic market risk and is fundamental to modern portfolio theory, cost of capital estimation, and risk management.\n\n2.  **Rolling-window estimation** captures time variation in betas, which reflects changes in companies' business models, leverage, and market conditions.\n\n3.  **Parallelization** dramatically reduces computation time for large-scale estimation tasks by distributing work across multiple CPU cores.\n\n4.  **Estimation choices matter**: Window length, return frequency, and minimum observation requirements all affect beta estimates. Researchers should choose parameters appropriate for their specific application.\n\n5.  **Industry patterns**: Vietnamese stocks show systematic differences in market sensitivity across industries, with cyclical sectors exhibiting higher betas than defensive sectors.\n\n6.  **Time variation**: The cross-sectional distribution of betas in Vietnam has evolved over time, with notable shifts during market stress periods.\n\n7.  **Frequency comparison**: Monthly and daily beta estimates are positively correlated but not identical. Daily estimates are smoother while monthly estimates may better capture lower-frequency variation.\n\n8.  **Data quality checks**: Coverage analysis and summary statistics help identify potential issues in estimation procedures before using results in downstream analyses.\n\n",
    "supporting": [
      "08_beta_estimation_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}